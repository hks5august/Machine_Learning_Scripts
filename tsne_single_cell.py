# -*- coding: utf-8 -*-
"""tSNE-single cell.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QBLoCrMVoAWuNb5fXOLRrEGDIO096w6r
"""

import pandas as pd

df = df = pd.read_csv('https://reneshbedre.github.io/assets/posts/tsne/ath_root_sub_seurat_processes.csv')
df = df.set_index(df.columns[0])
dft = df.T
dft = dft.set_index(dft.columns[0])

# check data
dft.head()

# as we have large number variables, we will first do to PCA to keep minimum number 
# of variables for t-SNE
from sklearn.decomposition import PCA
pca_scores = PCA().fit_transform(dft)

# create a dataframe of pca_scores
df_pc = pd.DataFrame(pca_scores)

# perform t-SNE on PCs scores
# we will use first 50 PCs but this can vary
# see that "verbose=1" prints out parameters on execution

from sklearn.manifold import TSNE
tsne_em = TSNE(n_components=2, perplexity=30.0, early_exaggeration=12, n_iter=1000, 
               learning_rate=368, verbose=1).fit_transform(df_pc.loc[:,0:49])

#check the output
tsne_em

from sklearn.cluster import DBSCAN
# here eps parameter is very important and optimizing eps is essential
# for well defined clusters. I have run DBSCAN with several eps values
# and got good clusters with eps=3
dbscan_m = DBSCAN(eps=3, min_samples=10).fit(tsne_em)

#dbscan_m.labels_
clabels = dbscan_m.labels_.tolist()

import matplotlib.pyplot as plt 

plt.figure(figsize=(10, 10))

#Plot scatterplot for K-means Clustering
scatter = plt.scatter(tsne_em[:,0],tsne_em[:,1], c = dbscan_m.labels_, cmap ='rainbow')
plt.xlabel('TSNE1') 
plt.ylabel('TSNE2')
plt.legend(*scatter.legend_elements())